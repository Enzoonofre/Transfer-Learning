# Transfer Learning

## ğŸ“Œ O que Ã© Transfer Learning?

Transfer Learning, ou Aprendizado por TransferÃªncia, Ã© uma tÃ©cnica que reaproveita um modelo de aprendizado de mÃ¡quina jÃ¡ treinado em um grande conjunto de dados para resolver um novo problema. Isso reduz drasticamente o tempo de treinamento e a necessidade de uma grande quantidade de dados, permitindo obter bons resultados com menos esforÃ§o computacional.

## ğŸš€ Como funciona?

A ideia Ã© simples! Em vez de treinar um modelo do zero, seguimos estas etapas:

1. **Carregar um modelo base** com pesos prÃ©-treinados.
2. **Congelar suas camadas**, para manter o conhecimento aprendido.
3. **Adicionar novas camadas** personalizadas para o seu problema.
4. **Treinar apenas as novas camadas** com seus prÃ³prios dados.

Dessa forma, aproveitamos o que jÃ¡ foi aprendido e ajustamos o modelo para nossa necessidade especÃ­fica.

---

## ğŸ”¹ Passo 1: Carregar um Modelo PrÃ©-Treinado

Ferramentas como o `Keras` jÃ¡ disponibilizam modelos prontos. Aqui estÃ¡ um exemplo usando o MobileNetV2:

```python
from tensorflow.keras.applications import MobileNetV2
import tensorflow as tf

pretrained_model = tf.keras.applications.MobileNetV2(
    include_top=False,  # Remove a Ãºltima camada de classificaÃ§Ã£o
    weights='imagenet'  # Usa pesos treinados na base ImageNet
)
```

ğŸ”¹ `weights='imagenet'` â†’ O modelo usarÃ¡ pesos prÃ©-treinados na base ImageNet.
ğŸ”¹ `include_top=False` â†’ Removemos a Ãºltima camada para personalizar a saÃ­da.

---

## ğŸ”¹ Passo 2: Congelar as Camadas do Modelo

Congelar as camadas significa que os pesos do modelo base nÃ£o serÃ£o alterados durante o treinamento. Isso impede que o modelo "desaprenda" o que jÃ¡ sabe.

```python
pretrained_model.trainable = False
```

Assim, as camadas prÃ©-treinadas continuam intactas e apenas as novas camadas serÃ£o ajustadas.

---

## ğŸ”¹ Passo 3: Criar um Novo Modelo

Agora adicionamos novas camadas para adaptar o modelo ao nosso problema especÃ­fico:

```python
from tensorflow.keras import models, layers

model = models.Sequential([
    pretrained_model,  # Modelo prÃ©-treinado
    layers.GlobalAveragePooling2D(),  # Camada de Pooling
    layers.Dense(2, activation='softmax')  # Camada final para classificaÃ§Ã£o em 2 classes
])
```

Aqui, adicionamos uma camada de pooling global e uma camada densa final com duas saÃ­das (para um problema de classificaÃ§Ã£o binÃ¡ria).

---

## ğŸ”¹ Passo 4: Compilar e Treinar o Modelo

Agora, basta compilar e treinar o modelo com seus novos dados:

```python
import tensorflow.keras as keras

model.compile(
    optimizer=keras.optimizers.Adam(),
    loss=keras.losses.BinaryCrossentropy(from_logits=True),
    metrics=[keras.metrics.BinaryAccuracy()]
)

model.fit(new_dataset, epochs=20, callbacks=[...], validation_data=...)
```

Isso ajustarÃ¡ apenas as novas camadas adicionadas, mantendo o aprendizado do modelo base.

---

## ğŸ¯ ConclusÃ£o

Transfer Learning Ã© uma maneira poderosa de economizar tempo e recursos computacionais, utilizando modelos prontos e adaptando-os para novos problemas. Ao seguir esse processo, vocÃª pode criar modelos eficientes sem precisar treinar tudo do zero.

### ğŸ”— PrÃ³ximos Passos:
âœ… Testar diferentes modelos prÃ©-treinados (ResNet, VGG, Inception, etc.)
âœ… Ajustar hiperparÃ¢metros para melhorar o desempenho
âœ… Explorar tÃ©cnicas de *fine-tuning* para liberar algumas camadas e refinÃ¡-las

---

ğŸ“Œ **Autor:** Enzo Onofre 
ğŸ“Œ **GitHub:** https://github.com/Enzoonofre
ğŸ“Œ **Contato:** enzo.onofre@ufu.br  

ğŸš€ **Agora Ã© sua vez!** Teste o Transfer Learning e veja como ele pode facilitar o desenvolvimento de modelos de aprendizado profundo. ğŸ˜ƒ

